{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da5a7da-3c93-4c28-8307-344c9603d804",
   "metadata": {},
   "source": [
    "## Setup jupyter notebook and install dependencies\n",
    "\n",
    "```\n",
    "python -m venv myenv\n",
    "source myenv/bin/activate\n",
    "pip install ipykernel\n",
    "pip install jupyter\n",
    "python -m ipykernel install --user --name=myenv\n",
    "jupyter notebook --ip 0.0.0.0 --port 8888\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c65f9b0-7d52-4647-b73d-cca8fc9a6148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertopic in ./myenv/lib/python3.9/site-packages (0.16.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in ./myenv/lib/python3.9/site-packages (from bertopic) (3.0.1)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in ./myenv/lib/python3.9/site-packages (from bertopic) (0.5.6)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in ./myenv/lib/python3.9/site-packages (from bertopic) (0.8.37)\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./myenv/lib/python3.9/site-packages (from bertopic) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in ./myenv/lib/python3.9/site-packages (from bertopic) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in ./myenv/lib/python3.9/site-packages (from bertopic) (1.5.1)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in ./myenv/lib/python3.9/site-packages (from bertopic) (4.66.4)\n",
      "Requirement already satisfied: plotly>=4.7.0 in ./myenv/lib/python3.9/site-packages (from bertopic) (5.22.0)\n",
      "Requirement already satisfied: cython<3,>=0.27 in ./myenv/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.37)\n",
      "Requirement already satisfied: joblib>=1.0 in ./myenv/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0 in ./myenv/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./myenv/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (8.5.0)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (24.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./myenv/lib/python3.9/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./myenv/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.42.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./myenv/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.24.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./myenv/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.3.1)\n",
      "Requirement already satisfied: Pillow in ./myenv/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (10.4.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in ./myenv/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
      "Requirement already satisfied: numba>=0.51.2 in ./myenv/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.12.2)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./myenv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./myenv/lib/python3.9/site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.4)\n",
      "Requirement already satisfied: sympy in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (8.9.2.26)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.0.2.54)\n",
      "Requirement already satisfied: triton==2.3.1 in ./myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./myenv/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.5.82)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./myenv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./myenv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./myenv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (2024.5.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/home/research/repositories/nlp_svensk/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nbformat>=4.2.0 in ./myenv/lib/python3.9/site-packages (5.10.4)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./myenv/lib/python3.9/site-packages (from nbformat>=4.2.0) (5.7.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in ./myenv/lib/python3.9/site-packages (from nbformat>=4.2.0) (4.23.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./myenv/lib/python3.9/site-packages (from nbformat>=4.2.0) (2.20.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in ./myenv/lib/python3.9/site-packages (from nbformat>=4.2.0) (5.14.3)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./myenv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0) (0.19.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./myenv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./myenv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./myenv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0) (0.35.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./myenv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0) (4.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/home/research/repositories/nlp_svensk/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tf-keras in ./myenv/lib/python3.9/site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17 in ./myenv/lib/python3.9/site-packages (from tf-keras) (2.17.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.0)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: keras>=3.2.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.65.1)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.9/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (58.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./myenv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in ./myenv/lib/python3.9/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: optree in ./myenv/lib/python3.9/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.12.1)\n",
      "Requirement already satisfied: namex in ./myenv/lib/python3.9/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2024.7.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./myenv/lib/python3.9/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./myenv/lib/python3.9/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./myenv/lib/python3.9/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./myenv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (8.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./myenv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib/python3.9/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./myenv/lib/python3.9/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./myenv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./myenv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/home/research/repositories/nlp_svensk/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openpyxl in ./myenv/lib/python3.9/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in ./myenv/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/home/research/repositories/nlp_svensk/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlsxwriter in ./myenv/lib/python3.9/site-packages (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/home/research/repositories/nlp_svensk/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: spacy in ./myenv/lib/python3.9/site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./myenv/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./myenv/lib/python3.9/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./myenv/lib/python3.9/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./myenv/lib/python3.9/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./myenv/lib/python3.9/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./myenv/lib/python3.9/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./myenv/lib/python3.9/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./myenv/lib/python3.9/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./myenv/lib/python3.9/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./myenv/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./myenv/lib/python3.9/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.9/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.9/site-packages (from spacy) (58.1.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./myenv/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./myenv/lib/python3.9/site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./myenv/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.9/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./myenv/lib/python3.9/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./myenv/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: language-data>=1.2 in ./myenv/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./myenv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./myenv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./myenv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./myenv/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./myenv/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./myenv/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./myenv/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./myenv/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./myenv/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./myenv/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.9/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./myenv/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./myenv/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in ./myenv/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./myenv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/home/research/repositories/nlp_svensk/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in ./myenv/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./myenv/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/home/research/repositories/nlp_svensk/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sv-core-news-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/sv_core_news_lg-3.7.0/sv_core_news_lg-3.7.0-py3-none-any.whl (228.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in ./myenv/lib/python3.9/site-packages (from sv-core-news-lg==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (0.12.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (4.66.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (24.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (58.1.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./myenv/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./myenv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./myenv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./myenv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./myenv/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./myenv/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./myenv/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./myenv/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: click>=8.0.0 in ./myenv/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./myenv/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (7.0.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./myenv/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (0.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./myenv/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./myenv/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: wrapt in ./myenv/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./myenv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->sv-core-news-lg==3.7.0) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/home/research/repositories/nlp_svensk/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('sv_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!pip install bertopic\n",
    "!pip install \"nbformat>=4.2.0\"\n",
    "!pip install tf-keras\n",
    "!pip install openpyxl\n",
    "#!pip install ipywidgets\n",
    "!pip install xlsxwriter\n",
    "#!pip install amphi-etl \n",
    "!pip install spacy\n",
    "!pip install pandas\n",
    "#!python -m spacy download sv_core_news_sm\n",
    "#!python -m spacy download sv_core_news_md\n",
    "!python -m spacy download sv_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fc0487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 19:29:35.105211: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-20 19:29:35.115802: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-20 19:29:35.119045: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-20 19:29:35.127019: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-20 19:29:35.704864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from miniArkivet import miniArkivet\n",
    "import multi_train\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15fe14",
   "metadata": {},
   "source": [
    "## Parser and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e157265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# miniArkivet parser\n",
    "from pathlib import Path\n",
    "Path(\"results/\").mkdir(parents=True, exist_ok=True)\n",
    "#df = miniArkivet(r\"tests\") # only few rows\n",
    "df = miniArkivet(r\"dummy\") # 15000 rows\n",
    "#df = miniArkivet(r\"tests\")\n",
    "df['alltext'] = df[['title', 'text']].apply('\\n'.join, axis=1)\n",
    "# df.to_excel(\"results/parsed_results.xlsx\", sheet_name='results')\n",
    "df.to_csv(\"results/parsed_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf9ab0",
   "metadata": {},
   "source": [
    "# load and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaca5f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>copyright</th>\n",
       "      <th>url</th>\n",
       "      <th>page</th>\n",
       "      <th>Published</th>\n",
       "      <th>bildtext</th>\n",
       "      <th>alltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to get all the child records from differen...</td>\n",
       "      <td>I am having 4 different tables like \\r\\nselect...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/34552974</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>How to get all the child records from differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retrieve all except some data of the another t...</td>\n",
       "      <td>I have two table m_master and tbl_appointment\\...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/34554721</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>Retrieve all except some data of the another t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pandas: read_html</td>\n",
       "      <td>&lt;p&gt;I'm trying to extract US states from wiki U...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/34555135</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>Pandas: read_html\\n&lt;p&gt;I'm trying to extract US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reader Always gimme NULL</td>\n",
       "      <td>I'm so new to C#, I wanna make an application ...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/34555448</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>Reader Always gimme NULL\\nI'm so new to C#, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>php rearrange array elements based on condition</td>\n",
       "      <td>basically i have this array:\\r\\n\\r\\n    array(...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/34555752</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>php rearrange array elements based on conditio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>How can I align two flex boxes to follow each ...</td>\n",
       "      <td>&lt;p&gt;I have a menu, and I'd like the div.right-c...</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/60465681</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>How can I align two flex boxes to follow each ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>C++ The correct way to multiply an integer and...</td>\n",
       "      <td>&lt;p&gt;I try to multiply an integer by a double bu...</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/60467932</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>C++ The correct way to multiply an integer and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>WHY DJANGO IS SHOWING ME THIS ERROR WHEN I TRY...</td>\n",
       "      <td>*URLS.PY*\\r\\n    //URLS.PY FILE\\r\\n    fro...</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/60468378</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>WHY DJANGO IS SHOWING ME THIS ERROR WHEN I TRY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>PHP - getting the content of php page</td>\n",
       "      <td>&lt;p&gt;I have a controller inside which a server i...</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/60469392</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>PHP - getting the content of php page\\n&lt;p&gt;I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>Why can't overloaded functions vary only by re...</td>\n",
       "      <td>&lt;p&gt;So i was recently helping someone out with ...</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>Hagens Knuheter</td>\n",
       "      <td>©Sonnier&lt;br&gt;</td>\n",
       "      <td>https://stackoverflow.com/questions/60470323</td>\n",
       "      <td>1</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>bild text</td>\n",
       "      <td>Why can't overloaded functions vary only by re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title                                               text        date        newspaper     copyright                                           url  page       Published   bildtext                                            alltext\n",
       "0      How to get all the child records from differen...  I am having 4 different tables like \\r\\nselect...  2016-01-01  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/34552974     1  stackoverflow   bild text  How to get all the child records from differen...\n",
       "1      Retrieve all except some data of the another t...  I have two table m_master and tbl_appointment\\...  2016-01-01  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/34554721     1  stackoverflow   bild text  Retrieve all except some data of the another t...\n",
       "2                                      Pandas: read_html  <p>I'm trying to extract US states from wiki U...  2016-01-01  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/34555135     1  stackoverflow   bild text  Pandas: read_html\\n<p>I'm trying to extract US...\n",
       "3                               Reader Always gimme NULL  I'm so new to C#, I wanna make an application ...  2016-01-01  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/34555448     1  stackoverflow   bild text  Reader Always gimme NULL\\nI'm so new to C#, I ...\n",
       "4        php rearrange array elements based on condition  basically i have this array:\\r\\n\\r\\n    array(...  2016-01-01  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/34555752     1  stackoverflow   bild text  php rearrange array elements based on conditio...\n",
       "...                                                  ...                                                ...         ...              ...           ...                                           ...   ...             ...        ...                                                ...\n",
       "14995  How can I align two flex boxes to follow each ...  <p>I have a menu, and I'd like the div.right-c...  2020-02-29  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/60465681     1  stackoverflow   bild text  How can I align two flex boxes to follow each ...\n",
       "14996  C++ The correct way to multiply an integer and...  <p>I try to multiply an integer by a double bu...  2020-02-29  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/60467932     1  stackoverflow   bild text  C++ The correct way to multiply an integer and...\n",
       "14997  WHY DJANGO IS SHOWING ME THIS ERROR WHEN I TRY...      *URLS.PY*\\r\\n    //URLS.PY FILE\\r\\n    fro...  2020-02-29  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/60468378     1  stackoverflow   bild text  WHY DJANGO IS SHOWING ME THIS ERROR WHEN I TRY...\n",
       "14998              PHP - getting the content of php page  <p>I have a controller inside which a server i...  2020-02-29  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/60469392     1  stackoverflow   bild text  PHP - getting the content of php page\\n<p>I ha...\n",
       "14999  Why can't overloaded functions vary only by re...  <p>So i was recently helping someone out with ...  2020-02-29  Hagens Knuheter  ©Sonnier<br>  https://stackoverflow.com/questions/60470323     1  stackoverflow   bild text  Why can't overloaded functions vary only by re...\n",
       "\n",
       "[15000 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formatted_time = \"...\"\n",
    "df = pd.read_csv(\"results/parsed_results.csv\")\n",
    "# import re\n",
    "# Optional data cleanup here\n",
    "#df.text = df.apply(lambda row: re.sub(r\"http\\S+\", \"\", row.text).lower(), 1)\n",
    "#df.text = df.apply(lambda row: \" \".join(filter(lambda x:x[0]!=\"@\", row.text.split())), 1)\n",
    "#df.text = df.apply(lambda row: \" \".join(re.sub(\"[^a-zA-Z]+\", \" \", row.text).split()), 1)\n",
    "\n",
    "# Source code generated by Amphi\n",
    "# Date: 2024-07-13 14:28:53\n",
    "# Additional dependencies: xlsxwriter\n",
    "#import pandas as pd\n",
    "\n",
    "# Reading data from 2024-07-12__18-43-parsed_results.csv\n",
    "csvFileInput1 = df\n",
    "\n",
    "# Deduplicate rows\n",
    "deduplicateData1 = csvFileInput1.drop_duplicates(subset=[\"title\", \"newspaper\", \"text\"])\n",
    "\n",
    "# Filter rows based on condition\n",
    "filter1 = deduplicateData1[~deduplicateData1['alltext'].str.contains(\"Ai Wei\", na=False)] #check spelling Ai Weiwei vs Ai Wei wei?\n",
    "filter2 = filter1[~filter1['date'].str.contains(\"1993\", na=False)] \n",
    "\n",
    "#TODO: remove Eslövs AI, EAI\n",
    "# Filter rows based on condition\n",
    "filter3 = filter2.dropna(subset=['text', 'date']) #removes articles with empty text fields\n",
    "\n",
    "#TODO: remove empty date\n",
    "#filter2.to_excel(\"testresults.xlsx\", engine='xlsxwriter', header=True)\n",
    "  \n",
    "df = filter3\n",
    "# df.to_excel(\"results/cleaned_results.xlsx\", sheet_name='results')\n",
    "df.to_csv(\"results/cleaned_results.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2f6b90f",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3a0483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KBLab/megatron-bert-large-swedish-cased-165k\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"KBLab/robust-swedish-sentiment-multiclass\")\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19600ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NEUTRAL', 0.9934292435646057)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentiment(sentence):\n",
    "    result = classifier(sentence)\n",
    "    return (result[0][\"label\"],result[0][\"score\"])\n",
    "\n",
    "sentiment(\"Elon Musk och Steven Hawking pratar om AI på Migrationsverket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['title_sent_label', 'title_sent_score']] = df['title'].apply(lambda t: pd.Series(sentiment(t)))\n",
    "df.to_csv(\"results/sent.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "725eed23",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"sv_core_news_lg\")\n",
    "\n",
    "def NER(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    persons = \"\"\n",
    "    orgs = \"\"\n",
    "    locations = \"\"\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_  == \"PRS\":\n",
    "            persons = persons + \",\" + ent.text\n",
    "        elif ent.label_  == \"ORG\":\n",
    "            orgs = orgs + \",\" + ent.text\n",
    "        elif ent.label_  == \"LOC\":\n",
    "            locations = locations + \",\" + ent.text\n",
    "    return  (orgs[1:], persons[1:], locations[1:])\n",
    "\n",
    "#TODO save values only once/ remove duplicates of entities\n",
    "\n",
    "#sentence = \"Elon Musk och Steven Hawking pratar om AI på Migrationsverket\"\n",
    "#print(NER(sentence))\n",
    "\n",
    "df[['ner_orgs', 'ner_persons', 'ner_loc']] = df['alltext'].apply(lambda t: pd.Series(NER(t)))\n",
    "df.to_csv(\"results/ner.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95b8b80c",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.dimensionality import BaseDimensionalityReduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca976652",
   "metadata": {},
   "source": [
    "## Default bertTopic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75ec54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "SEstopwords = [\"aderton\",\"adertonde\",\"adjö\",\"aldrig\",\"alla\",\"allas\",\"allt\",\"alltid\",\"alltså\",\"andra\",\"andras\",\"annan\",\"annat\",\"artonde\",\"artonn\",\"att\",\"av\",\"bakom\",\"bara\",\"behöva\",\"behövas\",\"behövde\",\"behövt\",\"beslut\",\"beslutat\",\"beslutit\",\"bland\",\"blev\",\"bli\",\"blir\",\"blivit\",\"bort\",\"borta\",\"bra\",\"bäst\",\"bättre\",\"båda\",\"bådas\",\"dag\",\"dagar\",\"dagarna\",\"dagen\",\"de\",\"del\",\"delen\",\"dem\",\"den\",\"denna\",\"deras\",\"dess\",\"dessa\",\"det\",\"detta\",\"dig\",\"din\",\"dina\",\"dit\",\"ditt\",\"dock\",\"dom\",\"du\",\"där\",\"därför\",\"då\",\"e\",\"efter\",\"eftersom\",\"ej\",\"elfte\",\"eller\",\"elva\",\"emot\",\"en\",\"enkel\",\"enkelt\",\"enkla\",\"enligt\",\"ens\",\"er\",\"era\",\"ers\",\"ert\",\"ett\",\"ettusen\",\"fanns\",\"fem\",\"femte\",\"femtio\",\"femtionde\",\"femton\",\"femtonde\",\"fick\",\"fin\",\"finnas\",\"finns\",\"fjorton\",\"fjortonde\",\"fjärde\",\"fler\",\"flera\",\"flesta\",\"fram\",\"framför\",\"från\",\"fyra\",\"fyrtio\",\"fyrtionde\",\"få\",\"får\",\"fått\",\"följande\",\"för\",\"före\",\"förlåt\",\"förra\",\"första\",\"genast\",\"genom\",\"gick\",\"gjorde\",\"gjort\",\"god\",\"goda\",\"godare\",\"godast\",\"gott\",\"gälla\",\"gäller\",\"gällt\",\"gärna\",\"gå\",\"går\",\"gått\",\"gör\",\"göra\",\"ha\",\"hade\",\"haft\",\"han\",\"hans\",\"har\",\"heller\",\"hellre\",\"helst\",\"helt\",\"henne\",\"hennes\",\"hit\",\"hon\",\"honom\",\"hundra\",\"hundraen\",\"hundraett\",\"hur\",\"här\",\"hög\",\"höger\",\"högre\",\"högst\",\"i\",\"ibland\",\"icke\",\"idag\",\"igen\",\"igår\",\"imorgon\",\"in\",\"inför\",\"inga\",\"ingen\",\"ingenting\",\"inget\",\"innan\",\"inne\",\"inom\",\"inte\",\"inuti\",\"ja\",\"jag\",\"jo\",\"ju\",\"just\",\"jämfört\",\"kan\",\"kanske\",\"knappast\",\"kom\",\"komma\",\"kommer\",\"kommit\",\"kr\",\"kunde\",\"kunna\",\"kunnat\",\"kvar\",\"legat\",\"ligga\",\"ligger\",\"lika\",\"likställd\",\"likställda\",\"lilla\",\"lite\",\"liten\",\"litet\",\"länge\",\"längre\",\"längst\",\"lätt\",\"lättare\",\"lättast\",\"långsam\",\"långsammare\",\"långsammast\",\"långsamt\",\"långt\",\"låt\",\"man\",\"med\",\"mej\",\"mellan\",\"men\",\"mer\",\"mera\",\"mest\",\"mig\",\"min\",\"mina\",\"mindre\",\"minst\",\"mitt\",\"mittemot\",\"mot\",\"mycket\",\"många\",\"måste\",\"möjlig\",\"möjligen\",\"möjligt\",\"möjligtvis\",\"ned\",\"nederst\",\"nedersta\",\"nedre\",\"nej\",\"ner\",\"ni\",\"nio\",\"nionde\",\"nittio\",\"nittionde\",\"nitton\",\"nittonde\",\"nog\",\"noll\",\"nr\",\"nu\",\"nummer\",\"när\",\"nästa\",\"någon\",\"någonting\",\"något\",\"några\",\"nån\",\"nånting\",\"nåt\",\"nödvändig\",\"nödvändiga\",\"nödvändigt\",\"nödvändigtvis\",\"och\",\"också\",\"ofta\",\"oftast\",\"olika\",\"olikt\",\"om\",\"oss\",\"på\",\"rakt\",\"redan\",\"rätt\",\"sa\",\"sade\",\"sagt\",\"samma\",\"sedan\",\"senare\",\"senast\",\"sent\",\"sex\",\"sextio\",\"sextionde\",\"sexton\",\"sextonde\",\"sig\",\"sin\",\"sina\",\"sist\",\"sista\",\"siste\",\"sitt\",\"sitta\",\"sju\",\"sjunde\",\"sjuttio\",\"sjuttionde\",\"sjutton\",\"sjuttonde\",\"själv\",\"sjätte\",\"ska\",\"skall\",\"skulle\",\"slutligen\",\"små\",\"smått\",\"snart\",\"som\",\"stor\",\"stora\",\"stort\",\"större\",\"störst\",\"säga\",\"säger\",\"sämre\",\"sämst\",\"så\",\"sådan\",\"sådana\",\"sådant\",\"ta\",\"tack\",\"tar\",\"tidig\",\"tidigare\",\"tidigast\",\"tidigt\",\"till\",\"tills\",\"tillsammans\",\"tio\",\"tionde\",\"tjugo\",\"tjugoen\",\"tjugoett\",\"tjugonde\",\"tjugotre\",\"tjugotvå\",\"tjungo\",\"tolfte\",\"tolv\",\"tre\",\"tredje\",\"trettio\",\"trettionde\",\"tretton\",\"trettonde\",\"två\",\"tvåhundra\",\"under\",\"upp\",\"ur\",\"ursäkt\",\"ut\",\"utan\",\"utanför\",\"ute\",\"va\",\"vad\",\"var\",\"vara\",\"varför\",\"varifrån\",\"varit\",\"varje\",\"varken\",\"vars\",\"varsågod\",\"vart\",\"vem\",\"vems\",\"verkligen\",\"vi\",\"vid\",\"vidare\",\"viktig\",\"viktigare\",\"viktigast\",\"viktigt\",\"vilka\",\"vilkas\",\"vilken\",\"vilket\",\"vill\",\"väl\",\"vänster\",\"vänstra\",\"värre\",\"vår\",\"våra\",\"vårt\",\"än\",\"ännu\",\"är\",\"även\",\"åt\",\"åtminstone\",\"åtta\",\"åttio\",\"åttionde\",\"åttonde\",\"över\",\"övermorgon\",\"överst\",\"övre\"]\n",
    "vectorizer_model = CountVectorizer(stop_words=SEstopwords)\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# Step 6 - (Optional) Fine-tune topic representations with \n",
    "# a `bertopic.representation` model\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "topic_model = BERTopic(\n",
    "      embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "      umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "      hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "      vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "      ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n",
    "      representation_model=representation_model # Step 6 - (Optional) Fine-tune topic represenations\n",
    "    )\n",
    "topics, probs = topic_model.fit_transform(df.text)\n",
    "topic_model.save(\"results/defaultBertTopic.pickle\", serialization=\"pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ba0d6-4f5c-498a-9d88-8068518a8e96",
   "metadata": {},
   "source": [
    "## Build all models (optional)\n",
    "\n",
    "To see configuration for each model, please see `multi_train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b6963-864d-420c-b825-188b8326befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results/ner.csv\")\n",
    "docs = df['alltext'].tolist()\n",
    "multi_train.build_all_models(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2533c",
   "metadata": {},
   "source": [
    "# Load model from file without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30344e-fa2d-47f8-973e-23dd2b7f6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "##list available models\n",
    "from bertopic import BERTopic\n",
    "print(glob.glob('./results/*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7a534-14fc-4cbb-ad50-d2112d4f2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it might cause problems to reload the topic model, preferred use is to run everything in the jupyter notebook again\n",
    "topic_model_file = \"results/defaultBertTopic.pickle\"\n",
    "topic_model= BERTopic.load(topic_model_file)\n",
    "freq = topic_model.get_topic_info(); freq.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed49036-a21d-4fba-ba46-e4f4ed8b97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda5a96-d4d8-4671-8d5f-984820dd7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_topics(); fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec82c3-0610-4c8f-a79b-878392976797",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(df['alltext'].tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe05703",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f1a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76510cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = df.date.to_list()\n",
    "alltexts = df.alltexts.to_list()\n",
    "print(len(timestamps), len(texts))\n",
    "topics_over_time = topic_model.topics_over_time(alltexts, timestamps, nr_bins=20)\n",
    "topic_model.visualize_topics_over_time(topics_over_time, topics=[10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all documents and their corresponding topic\n",
    "result = topic_model.get_document_info(df.text)\n",
    "result = result.drop(['Representation', 'Representative_Docs' ,'Top_n_words', 'Representative_document' ], axis=1)\n",
    "# result.to_csv('results/topic-docs.csv', index=False)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
