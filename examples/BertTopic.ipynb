{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "296f7a10",
   "metadata": {},
   "source": [
    "# Setup\n",
    "https://maartengr.github.io/BERTopic/getting_started/visualization/visualization.html#visualize-topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65f9b0-7d52-4647-b73d-cca8fc9a6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bertopic\n",
    "# !pip install nbformat>=4.2.0\n",
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.dimensionality import BaseDimensionalityReduction\n",
    "from miniArkivet import miniArkivet\n",
    "#df = miniArkivet(r\"C:\\Users\\frauker\\OneDrive - Chalmers\\Frauke\\Projects\\Agnotology of medical AI\\A-Media\\code\\2024-07-07BERTopic_testrun\")\n",
    "df = miniArkivet(r\"dummy\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf9ab0",
   "metadata": {},
   "source": [
    "# Data clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install amphi-etl \n",
    "#  AMPHI PIPELINE HERE\n",
    "# import re\n",
    "# Optional data cleanup here\n",
    "#df.text = df.apply(lambda row: re.sub(r\"http\\S+\", \"\", row.text).lower(), 1)\n",
    "#df.text = df.apply(lambda row: \" \".join(filter(lambda x:x[0]!=\"@\", row.text.split())), 1)\n",
    "#df.text = df.apply(lambda row: \" \".join(re.sub(\"[^a-zA-Z]+\", \" \", row.text).split()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8b80c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878908ee-5e16-457b-8a4c-948ed13ea299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def all_options():\n",
    "    # Step 1 - Extract embeddings\n",
    "    # KBLab/sentence-bert-swedish-cased\n",
    "    # all-MiniLM-L6-v2 : Default \n",
    "    # paraphrase-multilingual-MiniLM-L12-v2\n",
    "    embedding_model_0 = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "    embedding_model_1 = SentenceTransformer(\"KBLab/sentence-bert-swedish-cased\")\n",
    "\n",
    "    # Step 2 - Reduce dimensionality, n_components default value was 5\n",
    "    umap_model_0 = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "    umap_model_1 = UMAP(n_neighbors=15, n_components=10, min_dist=0.0, metric='cosine')\n",
    "\n",
    "    # Step 3 - Cluster reduced embeddings\n",
    "    hdbscan_model_0 = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "    hdbscan_model_1 = HDBSCAN(min_cluster_size=30, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "    # Step 4 - Tokenize topics\n",
    "    SEstopwords = [\"aderton\",\"adertonde\",\"adjö\",\"aldrig\",\"alla\",\"allas\",\"allt\",\"alltid\",\"alltså\",\"andra\",\"andras\",\"annan\",\"annat\",\"artonde\",\"artonn\",\"att\",\"av\",\"bakom\",\"bara\",\"behöva\",\"behövas\",\"behövde\",\"behövt\",\"beslut\",\"beslutat\",\"beslutit\",\"bland\",\"blev\",\"bli\",\"blir\",\"blivit\",\"bort\",\"borta\",\"bra\",\"bäst\",\"bättre\",\"båda\",\"bådas\",\"dag\",\"dagar\",\"dagarna\",\"dagen\",\"de\",\"del\",\"delen\",\"dem\",\"den\",\"denna\",\"deras\",\"dess\",\"dessa\",\"det\",\"detta\",\"dig\",\"din\",\"dina\",\"dit\",\"ditt\",\"dock\",\"dom\",\"du\",\"där\",\"därför\",\"då\",\"e\",\"efter\",\"eftersom\",\"ej\",\"elfte\",\"eller\",\"elva\",\"emot\",\"en\",\"enkel\",\"enkelt\",\"enkla\",\"enligt\",\"ens\",\"er\",\"era\",\"ers\",\"ert\",\"ett\",\"ettusen\",\"fanns\",\"fem\",\"femte\",\"femtio\",\"femtionde\",\"femton\",\"femtonde\",\"fick\",\"fin\",\"finnas\",\"finns\",\"fjorton\",\"fjortonde\",\"fjärde\",\"fler\",\"flera\",\"flesta\",\"fram\",\"framför\",\"från\",\"fyra\",\"fyrtio\",\"fyrtionde\",\"få\",\"får\",\"fått\",\"följande\",\"för\",\"före\",\"förlåt\",\"förra\",\"första\",\"genast\",\"genom\",\"gick\",\"gjorde\",\"gjort\",\"god\",\"goda\",\"godare\",\"godast\",\"gott\",\"gälla\",\"gäller\",\"gällt\",\"gärna\",\"gå\",\"går\",\"gått\",\"gör\",\"göra\",\"ha\",\"hade\",\"haft\",\"han\",\"hans\",\"har\",\"heller\",\"hellre\",\"helst\",\"helt\",\"henne\",\"hennes\",\"hit\",\"hon\",\"honom\",\"hundra\",\"hundraen\",\"hundraett\",\"hur\",\"här\",\"hög\",\"höger\",\"högre\",\"högst\",\"i\",\"ibland\",\"icke\",\"idag\",\"igen\",\"igår\",\"imorgon\",\"in\",\"inför\",\"inga\",\"ingen\",\"ingenting\",\"inget\",\"innan\",\"inne\",\"inom\",\"inte\",\"inuti\",\"ja\",\"jag\",\"jo\",\"ju\",\"just\",\"jämfört\",\"kan\",\"kanske\",\"knappast\",\"kom\",\"komma\",\"kommer\",\"kommit\",\"kr\",\"kunde\",\"kunna\",\"kunnat\",\"kvar\",\"legat\",\"ligga\",\"ligger\",\"lika\",\"likställd\",\"likställda\",\"lilla\",\"lite\",\"liten\",\"litet\",\"länge\",\"längre\",\"längst\",\"lätt\",\"lättare\",\"lättast\",\"långsam\",\"långsammare\",\"långsammast\",\"långsamt\",\"långt\",\"låt\",\"man\",\"med\",\"mej\",\"mellan\",\"men\",\"mer\",\"mera\",\"mest\",\"mig\",\"min\",\"mina\",\"mindre\",\"minst\",\"mitt\",\"mittemot\",\"mot\",\"mycket\",\"många\",\"måste\",\"möjlig\",\"möjligen\",\"möjligt\",\"möjligtvis\",\"ned\",\"nederst\",\"nedersta\",\"nedre\",\"nej\",\"ner\",\"ni\",\"nio\",\"nionde\",\"nittio\",\"nittionde\",\"nitton\",\"nittonde\",\"nog\",\"noll\",\"nr\",\"nu\",\"nummer\",\"när\",\"nästa\",\"någon\",\"någonting\",\"något\",\"några\",\"nån\",\"nånting\",\"nåt\",\"nödvändig\",\"nödvändiga\",\"nödvändigt\",\"nödvändigtvis\",\"och\",\"också\",\"ofta\",\"oftast\",\"olika\",\"olikt\",\"om\",\"oss\",\"på\",\"rakt\",\"redan\",\"rätt\",\"sa\",\"sade\",\"sagt\",\"samma\",\"sedan\",\"senare\",\"senast\",\"sent\",\"sex\",\"sextio\",\"sextionde\",\"sexton\",\"sextonde\",\"sig\",\"sin\",\"sina\",\"sist\",\"sista\",\"siste\",\"sitt\",\"sitta\",\"sju\",\"sjunde\",\"sjuttio\",\"sjuttionde\",\"sjutton\",\"sjuttonde\",\"själv\",\"sjätte\",\"ska\",\"skall\",\"skulle\",\"slutligen\",\"små\",\"smått\",\"snart\",\"som\",\"stor\",\"stora\",\"stort\",\"större\",\"störst\",\"säga\",\"säger\",\"sämre\",\"sämst\",\"så\",\"sådan\",\"sådana\",\"sådant\",\"ta\",\"tack\",\"tar\",\"tidig\",\"tidigare\",\"tidigast\",\"tidigt\",\"till\",\"tills\",\"tillsammans\",\"tio\",\"tionde\",\"tjugo\",\"tjugoen\",\"tjugoett\",\"tjugonde\",\"tjugotre\",\"tjugotvå\",\"tjungo\",\"tolfte\",\"tolv\",\"tre\",\"tredje\",\"trettio\",\"trettionde\",\"tretton\",\"trettonde\",\"två\",\"tvåhundra\",\"under\",\"upp\",\"ur\",\"ursäkt\",\"ut\",\"utan\",\"utanför\",\"ute\",\"va\",\"vad\",\"var\",\"vara\",\"varför\",\"varifrån\",\"varit\",\"varje\",\"varken\",\"vars\",\"varsågod\",\"vart\",\"vem\",\"vems\",\"verkligen\",\"vi\",\"vid\",\"vidare\",\"viktig\",\"viktigare\",\"viktigast\",\"viktigt\",\"vilka\",\"vilkas\",\"vilken\",\"vilket\",\"vill\",\"väl\",\"vänster\",\"vänstra\",\"värre\",\"vår\",\"våra\",\"vårt\",\"än\",\"ännu\",\"är\",\"även\",\"åt\",\"åtminstone\",\"åtta\",\"åttio\",\"åttionde\",\"åttonde\",\"över\",\"övermorgon\",\"överst\",\"övre\"]\n",
    "    vectorizer_model_0 = CountVectorizer(stop_words=SEstopwords)\n",
    "\n",
    "    # Step 5 - Create topic representation\n",
    "    ctfidf_model_0 = ClassTfidfTransformer()\n",
    "\n",
    "    # Step 6 - (Optional) Fine-tune topic representations with \n",
    "    # a `bertopic.representation` model\n",
    "    representation_model_0 = KeyBERTInspired()\n",
    "\n",
    "    options = [ [embedding_model_0, embedding_model_1], [umap_model_0, umap_model_1], [hdbscan_model_0, hdbscan_model_1] ,[vectorizer_model_0], [ctfidf_model_0], [representation_model_0]]\n",
    "    options_name = [ [\"embedding_model_0\", \"embedding_model_1\"], [\"umap_model_0\", \"umap_model_1\"], [\"hdbscan_model_0\", \"hdbscan_model_1\"] ,[\"vectorizer_model_0\"], [\"ctfidf_model_0\"], [\"representation_model_0\"]]\n",
    "    return (options, options_name)\n",
    "\n",
    "options, options_name = all_options()\n",
    "\n",
    "for (id, option) in  enumerate(itertools.product(*options)):\n",
    "    options, options_name = all_options() # RESET to make sure that objects and models are fresh\n",
    "    embedding_model,umap_model,hdbscan_model,vectorizer_model,ctfidf_model,representation_model = option \n",
    "    option_name = list(itertools.product(*options_name))[id]\n",
    "    option_string = ''.join([element + '-' for element in option_name])\n",
    "    print(\"Training\", option_string, \"a model for option:\",  option_name)\n",
    "    topic_model = BERTopic(\n",
    "      embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "      umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "      hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "      vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "      ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n",
    "      representation_model=representation_model # Step 6 - (Optional) Fine-tune topic represenations\n",
    "    )\n",
    "    topics, probs = topic_model.fit_transform(df.text)\n",
    "    topic_model.save(option_string + \".pickle\", serialization=\"pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2533c",
   "metadata": {},
   "source": [
    "# Load model from file without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0752fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_load = None\n",
    "topic_model_name = None\n",
    "def f(x):\n",
    "    global topic_model_load, topic_model_name\n",
    "    if x != '' : \n",
    "        topic_model_load= BERTopic.load(x)\n",
    "        print(\"loaded \", x)\n",
    "        topic_model_name = x\n",
    "trained_models = glob.glob('./*.pickle')\n",
    "interact(f, x=[''] + trained_models);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7a534-14fc-4cbb-ad50-d2112d4f2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = topic_model_load.get_topic_info(); freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed49036-a21d-4fba-ba46-e4f4ed8b97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_load.get_topic(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda5a96-d4d8-4671-8d5f-984820dd7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model_load.visualize_topics(); fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec82c3-0610-4c8f-a79b-878392976797",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_load.visualize_documents(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_load.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe05703",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_load.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_load.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f1a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_load.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76510cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = df.date.to_list()\n",
    "texts = df.text.to_list()\n",
    "topics_over_time = topic_model_load.topics_over_time(texts, timestamps, nr_bins=20)\n",
    "\n",
    "topic_model_load.visualize_topics_over_time(topics_over_time, topics=[1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all documents and their corresponding topic\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "result = topic_model_load.get_document_info(df.text)\n",
    "result = result.drop(['Representation', 'Representative_Docs' ,'Top_n_words', 'Representative_document' ], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce424a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(topic_model_name + 'topic-docs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693a018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
